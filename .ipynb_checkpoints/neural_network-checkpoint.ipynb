{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "216c2403-dafe-4e8d-9731-1de23cbd860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So far finished  0  epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Main\\AppData\\Local\\Temp\\ipykernel_17868\\2423631823.py:138: RuntimeWarning: overflow encountered in power\n",
      "  return 1/(1 + m.e**(-1*colVector))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So far finished  1  epoch\n",
      "So far finished  2  epoch\n",
      "So far finished  3  epoch\n",
      "So far finished  4  epoch\n",
      "So far finished  5  epoch\n",
      "So far finished  6  epoch\n",
      "So far finished  7  epoch\n",
      "So far finished  8  epoch\n",
      "So far finished  9  epoch\n",
      "So far finished  10  epoch\n",
      "So far finished  11  epoch\n",
      "So far finished  12  epoch\n",
      "So far finished  13  epoch\n",
      "So far finished  14  epoch\n",
      "0.1018\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "\n",
    "#IN ORDER TO RUN TRAINING, you'll need to download the .csv version of the MNIST dataset from https://www.kaggle.com/datasets/oddrationale/mnist-in-csv and place mnist_train.csv and mnist_test.csv\n",
    "#in the mnist-dataset directory.\n",
    "\n",
    "class Neural_Network:\n",
    "    \n",
    "    def __init__(self, layers, epochs, learningRate):\n",
    "        \n",
    "        self.layers = layers\n",
    "        self.epochs = epochs\n",
    "        self.learningRate = learningRate\n",
    "\n",
    "        #Reads in MNIST training set\n",
    "        self.data_initial = pd.read_csv('./mnist-dataset/mnist_train.csv')\n",
    "        self.labels = self.data_initial['label'] #(60000 imgs,)\n",
    "        self.data = self.data_initial.drop('label', axis=1) #(60000 imgs, 784, pixels)\n",
    "\n",
    "        #Reads in MNIST test set\n",
    "        self.testInitial = pd.read_csv('./mnist-dataset/mnist_test.csv')\n",
    "        self.testLabels = self.testInitial['label'] #(10000 imgs,)\n",
    "        self.testData = self.testInitial.drop('label', axis=1) #(10000 imgs, 784, pixels)\n",
    "\n",
    "        self.a_0 = np.empty([784, 1]) \n",
    "\n",
    "        self.W_1 = np.random.default_rng().normal(0, 1, size=(16,784))\n",
    "        self.b_1 = np.random.default_rng().normal(0, 1, size=(16,1))\n",
    "        self.z_1 = np.empty([16, 1])\n",
    "        self.a_1 = np.empty([16, 1])\n",
    "        self.error_1 = np.empty([16, 1])\n",
    "        \n",
    "        self.W_2 = np.random.default_rng().normal(0, 1, size=(16,16))\n",
    "        self.b_2 = np.random.default_rng().normal(0, 1, size=(16,1))\n",
    "        self.z_2 = np.empty([16, 1])\n",
    "        self.a_2 = np.empty([16, 1])\n",
    "        self.error_2 = np.empty([16, 1])\n",
    "       \n",
    "        self.W_3 = np.random.default_rng().normal(0, 1, size=(10,16))\n",
    "        self.b_3 = np.random.default_rng().normal(0, 1, size=(10,1))\n",
    "        self.z_3 = np.empty([10, 1])\n",
    "        self.a_3 = np.empty([10, 1])\n",
    "        self.error_out = np.empty([10, 1])\n",
    "        \n",
    "        self.y = np.zeros([1,10]) #This is a row vector, will be transposed. \n",
    "\n",
    "    def feedForward(self, x, dataset):\n",
    "        #Calculates all the activations in the network for the training example, x.\n",
    "\n",
    "        #Grabs image pixel information from the xth row of the dataset. \n",
    "        #This gives us a numpy (784,1) colm vector of activations for a training example, x, \n",
    "        #on Layer 0 (input layer)\n",
    "\n",
    "        #1 means feedForward a training example from the training dataset\n",
    "        if (dataset == 1):\n",
    "            self.a_0 = (self.data.iloc[x]).values.reshape((784,1))\n",
    "\n",
    "        #2 means feedForward a training example from the test dataset.\n",
    "        if (dataset == 2):\n",
    "            self.a_0 = (self.testData.iloc[x]).values.reshape((784,1))\n",
    "\n",
    "        #Going into Layer 1\n",
    "        self.z_1 = (np.dot(self.W_1, self.a_0)) + self.b_1\n",
    "        self.a_1 = self.sigmoid(self.z_1)\n",
    "\n",
    "        #Going into Layer 2\n",
    "        self.z_2 = (np.dot(self.W_2, self.a_1)) + self.b_2\n",
    "        self.a_2 = self.sigmoid(self.z_2)\n",
    "\n",
    "        #Going into Layer 3 (output layer)\n",
    "        self.z_3 = (np.dot(self.W_3, self.a_2)) + self.b_3\n",
    "        self.a_3 = self.sigmoid(self.z_3)\n",
    "        \n",
    "#    \n",
    "    def backProp(self, x): \n",
    "        #Calculates the \"error\" on all the neurons in the network for a training example, x.\n",
    "        \n",
    "        #Grabs label for the training example from the label column vector initialized at start.\n",
    "        #Then creates the y column vector that represents the ideal output for all the output neurons \n",
    "        #(for the spesific training example).\n",
    "        label = self.labels.iloc[x]\n",
    "        self.y[0,label] = label\n",
    "        self.y = np.transpose(self.y)\n",
    "        \n",
    "        #Calculuate the error on the output neurons\n",
    "        self.error_out = (self.a_3 - self.y) * self.dSigmoid(self.z_3)\n",
    "\n",
    "        #Calculate the error on each of neurons on each of the layers. Calculating backwards.\n",
    "        self.error_2 = np.dot((np.transpose(self.W_3)), self.error_out) * self.dSigmoid(self.z_2)\n",
    "\n",
    "        self.error_1 = np.dot((np.transpose(self.W_2)), self.error_2) * self.dSigmoid(self.z_1)\n",
    "\n",
    "        self.y = np.zeros([1,10])\n",
    "\n",
    "        #for (matrix)(colmVector) --> np.dot computes what we want.\n",
    "\n",
    "    def gradDescent(self):\n",
    "        #Updates all the weights and biases based on the calculated errors from backprop.\n",
    "                \n",
    "        self.W_1 = self.W_1 - self.learningRate*(np.dot(self.error_1, np.transpose(self.a_0)))\n",
    "        self.b_1 = self.b_1 - self.learningRate*(self.error_1)\n",
    "        \n",
    "        self.W_2 = self.W_2 - self.learningRate*(np.dot(self.error_2, np.transpose(self.a_1)))\n",
    "        self.b_2 = self.b_2 - self.learningRate*(self.error_2)\n",
    "\n",
    "        self.W_3 = self.W_3 - self.learningRate*(np.dot(self.error_out, np.transpose(self.a_2)))\n",
    "        self.b_3 = self.b_3 - self.learningRate*(self.error_out)\n",
    "\n",
    "    def startTraining(self):\n",
    "        for epochs in range(self.epochs):\n",
    "            print(\"So far finished \", epochs, \" epoch\")\n",
    "            for x in range(60000): #size of the MNIST dataset.\n",
    "                self.feedForward(x, 1)\n",
    "                self.backProp(x)\n",
    "                self.gradDescent()\n",
    "\n",
    "    def evaluate(self):\n",
    "        correct = 0\n",
    "        \n",
    "        for x in range(10000):\n",
    "            label = self.testLabels.iloc[x]\n",
    "            self.feedForward(x, 2)\n",
    "            \n",
    "            #Determine which activation is biggest in final layer\n",
    "            a_3R = (self.a_3).reshape(1,10).flatten()\n",
    "            \n",
    "            biggest = 0\n",
    "            theIndexOfBiggest = 0\n",
    "            for i in range(a_3R.size):\n",
    "                if (a_3R[i] > biggest):\n",
    "                    biggest = a_3R[i]\n",
    "                    theIndexOfBiggest = i\n",
    "\n",
    "            if (theIndexOfBiggest == label):\n",
    "                correct = correct + 1\n",
    "                \n",
    "        return (correct/10000)\n",
    "        \n",
    "    def sigmoid(self, colVector):\n",
    "        return 1/(1 + m.e**(-1*colVector))\n",
    "\n",
    "    def dSigmoid(self, colVector):\n",
    "        return (self.sigmoid(colVector)) * (1 - self.sigmoid(colVector))\n",
    "\n",
    "#12960 weights, 42 biases\n",
    "nn = Neural_Network(4, 2, 0.1)\n",
    "nn.startTraining()\n",
    "print(nn.evaluate())\n",
    "\n",
    "#So far, a very chopped implementation. \n",
    "#If you run this python program block, the model will train on 2 total epochs then evaluate the accuracy based on 10,000 test images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025610b6-56d1-4c87-967a-eb5b0d7374c3",
   "metadata": {},
   "source": [
    "### Reading in Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee101f51-88b1-41c3-8c8a-d51fbf53791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n",
      "(60000, 784)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#np.transpose works on pandas DataFrames\n",
    "\n",
    "data_initial = pd.read_csv('./mnist-dataset/mnist_train.csv')\n",
    "labels = data_initial['label']\n",
    "data = data_initial.drop('label', axis=1)\n",
    "\n",
    "#Sanity Check\n",
    "print(data_initial.shape)\n",
    "print(data.shape) #Should be (60000, 784), 60k training examples (rows), each 784 pixels\n",
    "print(labels.shape) #Should be (60000, ), 60k labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9385c6f-d2f0-445c-8fbc-535d77b32848",
   "metadata": {},
   "source": [
    "### Reading in a Image Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e316bab-4a57-4fe1-b3ba-2a5146b33283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1x1      0\n",
      "1x2      0\n",
      "1x3      0\n",
      "1x4      0\n",
      "1x5      0\n",
      "        ..\n",
      "28x24    0\n",
      "28x25    0\n",
      "28x26    0\n",
      "28x27    0\n",
      "28x28    0\n",
      "Name: 0, Length: 784, dtype: int64\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "# Returns 784,1 colm vector of the first img.\n",
    "\n",
    "firstImg = data.iloc[0]\n",
    "print(firstImg)\n",
    "print(firstImg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cd676b-7631-4e14-99b3-3ef3e3970cb1",
   "metadata": {},
   "source": [
    "### Reading in Label and Creating Y Colm Vector Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a3ab6a62-1a5d-46d3-9f23-5072477a7259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [5.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "y = np.zeros([1, 10])\n",
    "y0 = labels.iloc[0]\n",
    "y[0,y0] = y0\n",
    "y = np.transpose(y)\n",
    "\n",
    "print(y)\n",
    "\n",
    "#I currently don't think transpose OR reshaping to the transpose actually does anything."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f653016e-5ba9-42f1-8b37-75b8e6e46c1d",
   "metadata": {},
   "source": [
    "### Testing Why Gradient Descent is Broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aa76e5d8-df30-492d-b064-8c16cf214900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 1)\n",
      "[[-0.40528597 -0.40384543  0.09419205 ... -0.28404044  0.66003423\n",
      "   1.98236918]\n",
      " [-0.20340656 -1.18015369  1.25078338 ...  0.50561667  1.33540059\n",
      "  -0.58290972]\n",
      " [ 0.95574544 -0.32636246 -0.95895502 ...  0.62481656 -0.4425282\n",
      "   2.36529777]\n",
      " ...\n",
      " [-1.39743211 -0.96980717 -0.71149636 ... -0.77834672  1.31991467\n",
      "  -0.39134117]\n",
      " [-0.04281638  0.94211695 -0.02820208 ... -0.93458087 -0.08543699\n",
      "  -0.02447355]\n",
      " [-0.06146447 -0.32451686 -0.49651673 ... -0.32895833  0.76089135\n",
      "   0.03232471]]\n"
     ]
    }
   ],
   "source": [
    "W_1 = np.random.default_rng().normal(0, 1, size=(16,784))\n",
    "error_1 = np.empty([16, 1])\n",
    "learningRate = 0.1\n",
    "\n",
    "a_0 = (data.iloc[0]).values.reshape((784,1))\n",
    "print(a_0.shape)\n",
    "\n",
    "W_1 = W_1 - learningRate*(np.dot(error_1, np.transpose(a_0)))\n",
    "\n",
    "print(W_1)\n",
    "\n",
    "#Turns out, it was because my a_0 was still considered a panda series, not an numpy array. \n",
    "#That's why .transpose wasn't working."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5fa09-9a2c-4483-812a-2d3924f08a39",
   "metadata": {},
   "source": [
    "### Testing Why Feedforward is (Now) Broken, after using ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cac1fee2-9c14-422c-b019-c0fea7be7b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1)\n",
      "(16, 1)\n",
      "(10, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Main\\AppData\\Local\\Temp\\ipykernel_17928\\2044557122.py:9: RuntimeWarning: overflow encountered in power\n",
      "  return 1/(1 + m.e**(-1*colVector))\n"
     ]
    }
   ],
   "source": [
    "# I am going into this debug assuming that Feedforward broke on the first iteration on the model intially.\n",
    "# Not later.\n",
    "\n",
    "import math as m\n",
    "\n",
    "def sigmoid(colVector):\n",
    "    return 1/(1 + m.e**(-1*colVector))\n",
    "\n",
    "a_0 = (data.iloc[0]).values.reshape((784,1))\n",
    "\n",
    "W_1 = np.random.default_rng().normal(0, 1, size=(16,784))\n",
    "b_1 = np.random.default_rng().normal(0, 1, size=(16,1))\n",
    "\n",
    "W_2 = np.random.default_rng().normal(0, 1, size=(16,16))\n",
    "b_2 = np.random.default_rng().normal(0, 1, size=(16,1))\n",
    "\n",
    "W_3 = np.random.default_rng().normal(0, 1, size=(10,16))\n",
    "b_3 = np.random.default_rng().normal(0, 1, size=(10,1))\n",
    "\n",
    "#Going into Layer 1\n",
    "z_1 = (np.dot(W_1, a_0)) + b_1\n",
    "a_1 = sigmoid(z_1)\n",
    "print(a_1.shape)\n",
    "\n",
    "#Going into Layer 2\n",
    "z_2 = (np.dot(W_2, a_1)) + b_2\n",
    "a_2 = sigmoid(z_2)\n",
    "print(a_2.shape)\n",
    "\n",
    "#Going into Layer 3 (output layer)\n",
    "z_3 = (np.dot(W_3, a_2)) + b_3\n",
    "a_3 = sigmoid(z_3) \n",
    "print(a_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddde8cc-45f5-4e25-a99a-5a72e2e16d90",
   "metadata": {},
   "source": [
    "### Testing my Algorithm For Determing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83284f47-abd2-401f-b405-a40ac563c99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "0.9\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "testInitial = pd.read_csv('./mnist-dataset/mnist_test.csv')\n",
    "testLabels = testInitial['label'] #(10000 imgs,)\n",
    "testData = testInitial.drop('label', axis=1) #(10000 imgs, 784, pixels)\n",
    "correct = 0\n",
    "\n",
    "label = testLabels.iloc[0]\n",
    "\n",
    "#Determine which activation is biggest in final layer\n",
    "a_3R = np.array([0.2,0.3,0.1,0.5,0.1,0.2,0.4,0.9,0.3,0.8]) #7\n",
    "a_3R = np.array([0.2,0.3,0.1,0.5,0.1,0.2,0.4,0.7,0.3,0.8]) #9\n",
    "a_3R = np.array([0.2,0.3,0.1,0.9,0.1,0.2,0.4,0.3,0.3,0.6]) #4\n",
    "\n",
    "\n",
    "biggest = 0\n",
    "for i in range(a_3R.size):\n",
    "    if (a_3R[i] > biggest):\n",
    "        biggest = a_3R[i]\n",
    "        theIndexOfBiggest = i\n",
    "    #how do I now return the index of the biggest thing?\n",
    "        \n",
    "if (theIndexOfBiggest == label):\n",
    "    correct = correct + 1\n",
    "\n",
    "print(theIndexOfBiggest)\n",
    "print(biggest)\n",
    "print(correct/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6135d0dd-8ac8-4077-af8b-5b70a21a3da3",
   "metadata": {},
   "source": [
    "### Checking Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d339dcea-4e52-4b36-8d97-0e85ca1f662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n",
      "[[31]\n",
      " [71]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a_0 = np.array([1,2,3,4]).reshape(4,1)\n",
    "W_1 = np.array([[1,2,3,4], [5, 6, 7, 8]]).reshape(2,4)\n",
    "b_1 = np.array([[1], [1]]).reshape(2,1)\n",
    "z_1 = (np.dot(W_1, a_0)) + b_1\n",
    "\n",
    "print(a_0)\n",
    "print(W_1)\n",
    "print(z_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986625a6-317a-4ddd-9309-b908e9f99d04",
   "metadata": {},
   "source": [
    "### Checking Sigmoid (Old Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4268325-f39a-4bbb-b9a3-7419ef32f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "\n",
    "def sigmoid(colVector):\n",
    "    return 1/(1 + np.exp(-1*colVector))\n",
    "\n",
    "a_0 = np.arange(4).reshape(4, 1)\n",
    "W_1 = np.random.default_rng().normal(0, 1, size=(2,4))\n",
    "b_1 = np.random.default_rng().normal(0, 1, size=(2,1))\n",
    "z_1 = (np.dot(W_1, a_0)) + b_1\n",
    "\n",
    "a_1 = sigmoid(z_1)\n",
    "\n",
    "print(a_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba9ec76-d981-4c74-95a4-f3652238bc7b",
   "metadata": {},
   "source": [
    "### Checking Sigmoid Again (Old Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb10efc-b794-42d2-a576-fde63b417803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "\n",
    "def sigmoid(colVector):\n",
    "    return 1/(1 + np.exp(-1*colVector))\n",
    "\n",
    "a_0 = np.arange(784).reshape(784, 1)\n",
    "W_1 = np.random.default_rng().normal(0, 1, size=(16,784))\n",
    "b_1 = np.random.default_rng().normal(0, 1, size=(16,1))\n",
    "z_1 = (np.dot(W_1, a_0)) + b_1\n",
    "\n",
    "a_1 = sigmoid(z_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
